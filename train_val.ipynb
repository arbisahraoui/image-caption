{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import *\n",
    "from utils.load_data import *\n",
    "from config import config\n",
    "from pickle import load\n",
    "import random\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "random.seed(1035)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (img.jpg, list of captions)\n",
    "captions = getAllCaptions(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 6000.\n",
      "Done!\n",
      "Train images: 6000.\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "images_features_train, captions_train = load_image_features(config, 'train'), load_clean_data(config, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev images: 1000.\n",
      "Done!\n",
      "Dev images: 1000.\n"
     ]
    }
   ],
   "source": [
    "# Load the validation data\n",
    "images_features_val, captions_val = load_image_features(config, 'dev'), load_clean_data(config, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 34\n",
      "Train vocab size: 7579\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = create_tokenizer(captions_train)\n",
    "max_len = max_length(captions_train)\n",
    "print(f\"Max length: {max_len}\")\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Train vocab size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Model summary:\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 34)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 34, 256)      1940224     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4096)         0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 34, 256)      0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          1048832     ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 256)          525312      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 512)          0           ['dense_3[0][0]',                \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          131328      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7579)         1947803     ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,593,499\n",
      "Trainable params: 5,593,499\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = define_model(vocab_size, max_len)\n",
    "print('RNN Model summary:')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_train: 94, steps_val: 16\n",
      "Batch Size: 64\n",
      "Total Number of Epochs = 20\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save after each epoch\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "# Calculate steps\n",
    "steps_train = len(captions_train)//batch_size\n",
    "if len(captions_train)%batch_size!=0:\n",
    "    steps_train = steps_train+1\n",
    "steps_val = len(captions_val)//batch_size\n",
    "if len(captions_val)%batch_size!=0:\n",
    "    steps_val = steps_val+1\n",
    "\n",
    "# Checkpoints\n",
    "model_save_path = \"./model_data/model_RNN_epoch-{epoch:02d}_train_loss-{loss:.4f}_val_loss-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# Display infos\n",
    "print('steps_train: {}, steps_val: {}'.format(steps_train,steps_val))\n",
    "print('Batch Size: {}'.format(batch_size))\n",
    "print('Total Number of Epochs = {}'.format(epochs))\n",
    "\n",
    "# Shuffle train data\n",
    "ids_train = list(captions_train.keys())\n",
    "random.shuffle(ids_train)\n",
    "captions_train_shuffled = {_id: captions_train[_id] for _id in ids_train}\n",
    "caps_train = captions_train_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 05:10:47.919666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 5.6360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 05:16:46.555089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.86529, saving model to ./model_data/model_RNN_epoch-01_train_loss-5.6360_val_loss-4.8653.hdf5\n",
      "94/94 [==============================] - 399s 4s/step - loss: 5.6360 - val_loss: 4.8653\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 4.4692\n",
      "Epoch 2: val_loss improved from 4.86529 to 4.16248, saving model to ./model_data/model_RNN_epoch-02_train_loss-4.4692_val_loss-4.1625.hdf5\n",
      "94/94 [==============================] - 335s 4s/step - loss: 4.4692 - val_loss: 4.1625\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 3.8869\n",
      "Epoch 3: val_loss improved from 4.16248 to 3.93021, saving model to ./model_data/model_RNN_epoch-03_train_loss-3.8869_val_loss-3.9302.hdf5\n",
      "94/94 [==============================] - 333s 4s/step - loss: 3.8869 - val_loss: 3.9302\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 3.5767\n",
      "Epoch 4: val_loss improved from 3.93021 to 3.84140, saving model to ./model_data/model_RNN_epoch-04_train_loss-3.5767_val_loss-3.8414.hdf5\n",
      "94/94 [==============================] - 331s 4s/step - loss: 3.5767 - val_loss: 3.8414\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 3.3597\n",
      "Epoch 5: val_loss improved from 3.84140 to 3.81726, saving model to ./model_data/model_RNN_epoch-05_train_loss-3.3597_val_loss-3.8173.hdf5\n",
      "94/94 [==============================] - 334s 4s/step - loss: 3.3597 - val_loss: 3.8173\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 3.1825\n",
      "Epoch 6: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 331s 4s/step - loss: 3.1825 - val_loss: 3.8405\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 3.0421\n",
      "Epoch 7: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 329s 4s/step - loss: 3.0421 - val_loss: 3.8592\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.9228\n",
      "Epoch 8: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 330s 4s/step - loss: 2.9228 - val_loss: 3.9040\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.8246\n",
      "Epoch 9: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 330s 4s/step - loss: 2.8246 - val_loss: 3.9107\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.7385\n",
      "Epoch 10: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 348s 4s/step - loss: 2.7385 - val_loss: 3.9253\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.6627\n",
      "Epoch 11: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 330s 4s/step - loss: 2.6627 - val_loss: 3.9485\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.5929\n",
      "Epoch 12: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 329s 4s/step - loss: 2.5929 - val_loss: 3.9515\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.5364\n",
      "Epoch 13: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 385s 4s/step - loss: 2.5364 - val_loss: 3.9646\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.4815\n",
      "Epoch 14: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 361s 4s/step - loss: 2.4815 - val_loss: 3.9818\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.4288\n",
      "Epoch 15: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 369s 4s/step - loss: 2.4288 - val_loss: 3.9937\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.3821\n",
      "Epoch 16: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 359s 4s/step - loss: 2.3821 - val_loss: 4.0465\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.3416\n",
      "Epoch 17: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 337s 4s/step - loss: 2.3416 - val_loss: 4.0612\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.3021\n",
      "Epoch 18: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 329s 4s/step - loss: 2.3021 - val_loss: 4.0893\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.2659\n",
      "Epoch 19: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 331s 4s/step - loss: 2.2659 - val_loss: 4.1035\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 2.2281\n",
      "Epoch 20: val_loss did not improve from 3.81726\n",
      "94/94 [==============================] - 330s 4s/step - loss: 2.2281 - val_loss: 4.1384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03976e7730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the train data generator\n",
    "# returns [[img_features, text_features], out_word]\n",
    "generator_train = data_generator(images_features_train, caps_train, tokenizer, max_len, batch_size, 1035)\n",
    "# Create the validation data generator\n",
    "# returns [[img_features, text_features], out_word]\n",
    "generator_val = data_generator(images_features_val, captions_val, tokenizer, max_len, batch_size, 1035)\n",
    "\n",
    "# Fit for one epoch\n",
    "model.fit(generator_train, epochs=epochs, steps_per_epoch=steps_train, validation_data=generator_val, validation_steps=steps_val, callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully. Running model on validation set for calculating BLEU score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 799/1000 [24:03<07:02,  2.10s/it]  "
     ]
    }
   ],
   "source": [
    "#Evaluate the model on validation data and ouput BLEU score\n",
    "\n",
    "print('Model trained successfully. Running model on validation set for calculating BLEU score')\n",
    "evaluate_model(model, images_features_val, captions_val, tokenizer, max_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
